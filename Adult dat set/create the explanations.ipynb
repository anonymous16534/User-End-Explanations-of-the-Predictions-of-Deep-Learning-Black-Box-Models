{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7179,
     "status": "ok",
     "timestamp": 1640171467954,
     "user": {
      "displayName": "Rami Haffar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GivN-4FkTKiDKvMHhlJwv31uylfJn0gB7E9jeMk=s64",
      "userId": "01415100011876379673"
     },
     "user_tz": -60
    },
    "id": "_gVzYL5sSS5I"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 732,
     "status": "ok",
     "timestamp": 1640171485599,
     "user": {
      "displayName": "Rami Haffar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GivN-4FkTKiDKvMHhlJwv31uylfJn0gB7E9jeMk=s64",
      "userId": "01415100011876379673"
     },
     "user_tz": -60
    },
    "id": "smKvqvL4SbCZ"
   },
   "outputs": [],
   "source": [
    "# read the adult data set\n",
    "adult_data = pd.read_csv('adult_data.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1640171485600,
     "user": {
      "displayName": "Rami Haffar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GivN-4FkTKiDKvMHhlJwv31uylfJn0gB7E9jeMk=s64",
      "userId": "01415100011876379673"
     },
     "user_tz": -60
    },
    "id": "V8IdKRUaSbEh",
    "outputId": "52344844-b60c-4c6b-e541-5057c364cbf6"
   },
   "outputs": [],
   "source": [
    "# removing the non values and the two features fnlwgt and education\n",
    "adult_data.dropna(inplace=True)\n",
    "adult_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Drop fnlwgt, not interesting for ML\n",
    "adult_data.drop('fnlwgt', axis=1, inplace=True)\n",
    "adult_data.drop('education', axis=1, inplace=True)\n",
    "\n",
    "#Data columns and their types\n",
    "adult_data.info()\n",
    "adult_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1640171485600,
     "user": {
      "displayName": "Rami Haffar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GivN-4FkTKiDKvMHhlJwv31uylfJn0gB7E9jeMk=s64",
      "userId": "01415100011876379673"
     },
     "user_tz": -60
    },
    "id": "Z5GG11HBSbHR"
   },
   "outputs": [],
   "source": [
    "# incoding the marital-status into married or unmarried\n",
    "adult_data['marital-status'].replace('Married-civ-spouse', 'Married', inplace=True)\n",
    "adult_data['marital-status'].replace('Divorced', 'Unmarried', inplace=True)\n",
    "adult_data['marital-status'].replace('Never-married', 'Unmarried', inplace=True)\n",
    "adult_data['marital-status'].replace('Separated', 'Unmarried', inplace=True)\n",
    "adult_data['marital-status'].replace('Widowed', 'Unmarried', inplace=True)\n",
    "adult_data['marital-status'].replace('Married-spouse-absent', 'Married', inplace=True)\n",
    "adult_data['marital-status'].replace('Married-AF-spouse', 'Married', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 219,
     "status": "ok",
     "timestamp": 1640171485811,
     "user": {
      "displayName": "Rami Haffar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GivN-4FkTKiDKvMHhlJwv31uylfJn0gB7E9jeMk=s64",
      "userId": "01415100011876379673"
     },
     "user_tz": -60
    },
    "id": "LCbabRh3SbMu"
   },
   "outputs": [],
   "source": [
    "obj_columns = adult_data.select_dtypes(['object']).columns\n",
    "adult_data[obj_columns] = adult_data[obj_columns].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 826
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1640171485812,
     "user": {
      "displayName": "Rami Haffar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GivN-4FkTKiDKvMHhlJwv31uylfJn0gB7E9jeMk=s64",
      "userId": "01415100011876379673"
     },
     "user_tz": -60
    },
    "id": "BMiXSDZ3SbPN",
    "outputId": "c6b1418b-a18f-43eb-c8b2-cee7f4949df1"
   },
   "outputs": [],
   "source": [
    "# Convert numerics to floats \n",
    "num_columns = adult_data.select_dtypes(['int64']).columns\n",
    "adult_data[num_columns] = adult_data[num_columns].astype('float64')\n",
    "# encoding the categorical attributes into numerical\n",
    "marital_status = dict(zip(adult_data['income'].cat.codes, adult_data['income']))\n",
    "adult_data['income'] = adult_data['income'].cat.codes\n",
    "marital_status = dict(zip(adult_data['marital-status'].cat.codes, adult_data['marital-status']))\n",
    "adult_data['marital-status'] = adult_data['marital-status'].cat.codes\n",
    "occupation = dict(zip(adult_data['occupation'].cat.codes, adult_data['occupation']))\n",
    "adult_data['occupation'] = adult_data['occupation'].cat.codes\n",
    "relationship = dict(zip(adult_data['relationship'].cat.codes, adult_data['relationship']))\n",
    "adult_data['relationship'] = adult_data['relationship'].cat.codes\n",
    "race = dict(zip(adult_data['race'].cat.codes, adult_data['race']))\n",
    "adult_data['race'] = adult_data['race'].cat.codes\n",
    "gender = dict(zip(adult_data['gender'].cat.codes, adult_data['gender']))\n",
    "adult_data['gender'] = adult_data['gender'].cat.codes\n",
    "native_country = dict(zip(adult_data['native-country'].cat.codes, adult_data['native-country']))\n",
    "adult_data['native-country'] = adult_data['native-country'].cat.codes\n",
    "workclass = dict(zip(adult_data['workclass'].cat.codes, adult_data['workclass']))\n",
    "adult_data['workclass'] = adult_data['workclass'].cat.codes\n",
    "\n",
    "num_columns = adult_data.select_dtypes(['int8']).columns\n",
    "adult_data[num_columns] = adult_data[num_columns].astype('float64')\n",
    "\n",
    "display(adult_data.info())\n",
    "display(adult_data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1640171486029,
     "user": {
      "displayName": "Rami Haffar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GivN-4FkTKiDKvMHhlJwv31uylfJn0gB7E9jeMk=s64",
      "userId": "01415100011876379673"
     },
     "user_tz": -60
    },
    "id": "vFbdt3pkSbSB"
   },
   "outputs": [],
   "source": [
    "# convert the data set from pandas to numpy\n",
    "adult_data = adult_data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1640171486029,
     "user": {
      "displayName": "Rami Haffar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GivN-4FkTKiDKvMHhlJwv31uylfJn0gB7E9jeMk=s64",
      "userId": "01415100011876379673"
     },
     "user_tz": -60
    },
    "id": "ac1myEbNSbUa"
   },
   "outputs": [],
   "source": [
    "# spliting the data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(adult_data[:,:-1],adult_data[:,-1], test_size=0.2, random_state=92)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1640171486030,
     "user": {
      "displayName": "Rami Haffar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GivN-4FkTKiDKvMHhlJwv31uylfJn0gB7E9jeMk=s64",
      "userId": "01415100011876379673"
     },
     "user_tz": -60
    },
    "id": "_HzeyZPI30d0"
   },
   "outputs": [],
   "source": [
    "# normalizing the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 245,
     "status": "ok",
     "timestamp": 1640171487198,
     "user": {
      "displayName": "Rami Haffar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GivN-4FkTKiDKvMHhlJwv31uylfJn0gB7E9jeMk=s64",
      "userId": "01415100011876379673"
     },
     "user_tz": -60
    },
    "id": "FEXtRyiR5geE"
   },
   "outputs": [],
   "source": [
    "# the attributes names\n",
    "names = ['age','workclass','educational-num','marital-status','occupation','relationship','race','gender','capital-gain','capital-loss','hours-per-week','native-country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 168,
     "status": "ok",
     "timestamp": 1640171553181,
     "user": {
      "displayName": "Rami Haffar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GivN-4FkTKiDKvMHhlJwv31uylfJn0gB7E9jeMk=s64",
      "userId": "01415100011876379673"
     },
     "user_tz": -60
    },
    "id": "3ZVhk5vwStGW"
   },
   "outputs": [],
   "source": [
    "## train data\n",
    "class TrainData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "\n",
    "train_data = TrainData(torch.FloatTensor(X_train), \n",
    "                       torch.FloatTensor(y_train))\n",
    "## test data    \n",
    "class TestData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "\n",
    "test_data = TestData(torch.FloatTensor(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 170,
     "status": "ok",
     "timestamp": 1640171555228,
     "user": {
      "displayName": "Rami Haffar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GivN-4FkTKiDKvMHhlJwv31uylfJn0gB7E9jeMk=s64",
      "userId": "01415100011876379673"
     },
     "user_tz": -60
    },
    "id": "VkxmQ7o-StJA"
   },
   "outputs": [],
   "source": [
    "# the hyper parametes of the original model\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1640171556257,
     "user": {
      "displayName": "Rami Haffar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GivN-4FkTKiDKvMHhlJwv31uylfJn0gB7E9jeMk=s64",
      "userId": "01415100011876379673"
     },
     "user_tz": -60
    },
    "id": "g1ML_V73StLh"
   },
   "outputs": [],
   "source": [
    "# the data loader for the provider model\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1640171557059,
     "user": {
      "displayName": "Rami Haffar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GivN-4FkTKiDKvMHhlJwv31uylfJn0gB7E9jeMk=s64",
      "userId": "01415100011876379673"
     },
     "user_tz": -60
    },
    "id": "MqnscH3TStN_"
   },
   "outputs": [],
   "source": [
    "# models\n",
    "\n",
    "class provider_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BinaryClassification, self).__init__()\n",
    "        # Number of input features is 12.\n",
    "        self.layer_1 = nn.Linear(12, 100) \n",
    "        self.layer_2 = nn.Linear(100, 100)\n",
    "        self.layer_out = nn.Linear(100, 1) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(100)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(100)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x\n",
    "class user_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BinaryClassification, self).__init__()\n",
    "        # Number of input features is 12.\n",
    "        self.layer_1 = nn.Linear(12, 64) \n",
    "        self.layer_2 = nn.Linear(64, 64)\n",
    "        self.layer_out = nn.Linear(64, 1) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(64)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(64)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 180,
     "status": "ok",
     "timestamp": 1640171558515,
     "user": {
      "displayName": "Rami Haffar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GivN-4FkTKiDKvMHhlJwv31uylfJn0gB7E9jeMk=s64",
      "userId": "01415100011876379673"
     },
     "user_tz": -60
    },
    "id": "Nl75erszStQl",
    "outputId": "5b380f6e-c091-40fe-8b35-c4c843b7f450"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8520,
     "status": "ok",
     "timestamp": 1640171567968,
     "user": {
      "displayName": "Rami Haffar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GivN-4FkTKiDKvMHhlJwv31uylfJn0gB7E9jeMk=s64",
      "userId": "01415100011876379673"
     },
     "user_tz": -60
    },
    "id": "YNec2AlJStTI",
    "outputId": "0d061cbe-a82a-4f13-f42c-c19d7ebbe068"
   },
   "outputs": [],
   "source": [
    "# read the provider model\n",
    "model = provider_model()\n",
    "model.to(device)\n",
    "print(model)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "model.load_state_dict(torch.load('original_model.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1640171568283,
     "user": {
      "displayName": "Rami Haffar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GivN-4FkTKiDKvMHhlJwv31uylfJn0gB7E9jeMk=s64",
      "userId": "01415100011876379673"
     },
     "user_tz": -60
    },
    "id": "WY-tIqRjStYJ",
    "outputId": "fd3a8c7b-906d-40d2-ad64-b8e0c300f565"
   },
   "outputs": [],
   "source": [
    "# read the user surrogate model\n",
    "local_model = user_model()\n",
    "local_model.to(device)\n",
    "print(local_model)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(local_model.parameters(), lr=LEARNING_RATE)\n",
    "local_model.load_state_dict(torch.load('/content/gdrive/MyDrive/work/adult/local_model.pth'))\n",
    "local_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1640171568284,
     "user": {
      "displayName": "Rami Haffar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GivN-4FkTKiDKvMHhlJwv31uylfJn0gB7E9jeMk=s64",
      "userId": "01415100011876379673"
     },
     "user_tz": -60
    },
    "id": "hCS3E3CaTB5w"
   },
   "outputs": [],
   "source": [
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1640171568511,
     "user": {
      "displayName": "Rami Haffar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GivN-4FkTKiDKvMHhlJwv31uylfJn0gB7E9jeMk=s64",
      "userId": "01415100011876379673"
     },
     "user_tz": -60
    },
    "id": "oGEfJzcETB8P"
   },
   "outputs": [],
   "source": [
    "# check for the wrongly classified records by the provider model\n",
    "def test(original_model, device, local_test_loader, targets):\n",
    "\n",
    "    # Accuracy counter\n",
    "    correct = 0\n",
    "    wrong_examples = []\n",
    "    true_labels = []\n",
    "    wrong_labels = []\n",
    "    counter = 0\n",
    "    bad_answer = 0\n",
    "\n",
    "    # Loop over all examples in test set\n",
    "    for temp in local_test_loader:\n",
    "        counter += 1\n",
    "        data = temp\n",
    "        target = targets[counter-1]\n",
    "\n",
    "        # Send the data and label to the device\n",
    "        data = data.to(device) \n",
    "\n",
    "        # Forward pass the data through the model\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            output = model(data)\n",
    "            output = torch.sigmoid(output)\n",
    "            final_pred = torch.round(output)\n",
    "        if final_pred.item() == target:\n",
    "            # print('ture')\n",
    "            correct += 1\n",
    "        else:\n",
    "            wrong_examples.append(data)\n",
    "            true_labels.append(target)\n",
    "            wrong_labels.append(final_pred.item())\n",
    "            bad_answer  = bad_answer+1\n",
    "\n",
    "    \n",
    "    # Calculate final accuracy for this epsilon\n",
    "    final_acc = correct/float(len(local_test_loader))\n",
    "\n",
    "    # Return the accuracy and an adversarial example\n",
    "    return final_acc, wrong_examples, true_labels, wrong_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2574,
     "status": "ok",
     "timestamp": 1640171571567,
     "user": {
      "displayName": "Rami Haffar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GivN-4FkTKiDKvMHhlJwv31uylfJn0gB7E9jeMk=s64",
      "userId": "01415100011876379673"
     },
     "user_tz": -60
    },
    "id": "iAQFvm21TIra"
   },
   "outputs": [],
   "source": [
    "final_acc, wrong_examples, true_labels, wrong_labels = test(model, device, test_loader, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1640171572262,
     "user": {
      "displayName": "Rami Haffar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GivN-4FkTKiDKvMHhlJwv31uylfJn0gB7E9jeMk=s64",
      "userId": "01415100011876379673"
     },
     "user_tz": -60
    },
    "id": "DpcAZPOzTirD",
    "outputId": "43902c92-9fbe-43b1-b7ae-bf6aea8cd9fb"
   },
   "outputs": [],
   "source": [
    "len(wrong_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 349,
     "status": "ok",
     "timestamp": 1640171604840,
     "user": {
      "displayName": "Rami Haffar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GivN-4FkTKiDKvMHhlJwv31uylfJn0gB7E9jeMk=s64",
      "userId": "01415100011876379673"
     },
     "user_tz": -60
    },
    "id": "OGvBw2-n__sj",
    "outputId": "24abb420-7eb0-4e08-e2f6-98223a2f4357"
   },
   "outputs": [],
   "source": [
    "wrong_labels[499]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 198,
     "status": "ok",
     "timestamp": 1640173009804,
     "user": {
      "displayName": "Rami Haffar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GivN-4FkTKiDKvMHhlJwv31uylfJn0gB7E9jeMk=s64",
      "userId": "01415100011876379673"
     },
     "user_tz": -60
    },
    "id": "BbxwIB3nTIuA",
    "outputId": "1c05ed7a-0149-4a0a-8b59-84735f3fe27a"
   },
   "outputs": [],
   "source": [
    "# adding the perturbations to create the counterfactual example.\n",
    "perturbed_examples = []\n",
    "original_wrong_examples = []\n",
    "new_labels = []\n",
    "eps_all = []\n",
    "counter = 0\n",
    "# the list of features the user selects to be changed\n",
    "list_of_features = [0,2,10]\n",
    "\n",
    "for i in range(len(wrong_examples)):\n",
    "    x, y, prediction = wrong_examples[i], true_labels[i], wrong_labels[i]\n",
    "    print(prediction)\n",
    "    eps = 0.0\n",
    "    while True:\n",
    "        y =  float(y)\n",
    "        y = torch.tensor([[y]])\n",
    "        y = y.to(device)\n",
    "        counter = counter + 1\n",
    "        perturbed_image = x.clone()\n",
    "        perturbed_image.requires_grad = True\n",
    "        local_model.eval()\n",
    "        output = local_model(perturbed_image)\n",
    "        output = torch.sigmoid(output)\n",
    "        loss = criterion(output, y)\n",
    "        output = torch.round(output)\n",
    "        loss.backward()\n",
    "        img_grad = perturbed_image.grad.data\n",
    "        with torch.no_grad():\n",
    "#         adding the perturbations according to the user preference\n",
    "            if list_of_features:\n",
    "                for h in range(len(img_grad[0])):\n",
    "                    if int(h)  in list_of_features:\n",
    "                        perturbed_image[0][h] = perturbed_image[0][h] - eps*img_grad[0][h]\n",
    "#             if the user did not select a preference\n",
    "            else:\n",
    "                perturbed_image = perturbed_image - eps*img_grad\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            output = model(perturbed_image)\n",
    "            output = torch.sigmoid(output)\n",
    "            output = torch.round(output)\n",
    "        new_label = output.item()\n",
    "        if(new_label == y):\n",
    "            perturbed_examples.append(perturbed_image.squeeze().data.cpu().numpy())\n",
    "            original_wrong_examples.append(x.squeeze().data.cpu().numpy())\n",
    "            new_labels.append(new_label)\n",
    "            eps_all.append(eps)\n",
    "            print(\"Image {} has been modified with epsilon {}\".format(i, eps))\n",
    "            break\n",
    "        eps += 0.5\n",
    "        if eps > 100:\n",
    "            print('there are not example')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1640173012390,
     "user": {
      "displayName": "Rami Haffar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GivN-4FkTKiDKvMHhlJwv31uylfJn0gB7E9jeMk=s64",
      "userId": "01415100011876379673"
     },
     "user_tz": -60
    },
    "id": "AE4sEouCOShh"
   },
   "outputs": [],
   "source": [
    "# inverse the normalization of the data set\n",
    "inversed_perturbed_examples = scaler.inverse_transform(perturbed_examples)\n",
    "inversed_original_wrong_examples = scaler.inverse_transform(original_wrong_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 530
    },
    "executionInfo": {
     "elapsed": 195,
     "status": "error",
     "timestamp": 1640173013480,
     "user": {
      "displayName": "Rami Haffar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GivN-4FkTKiDKvMHhlJwv31uylfJn0gB7E9jeMk=s64",
      "userId": "01415100011876379673"
     },
     "user_tz": -60
    },
    "id": "nMmQxU3hOSme",
    "outputId": "b6f68f79-3966-4691-ed0f-cf2e6402f605"
   },
   "outputs": [],
   "source": [
    "# print the counterfactual examples with its categorical values\n",
    "temp = inversed_perturbed_examples\n",
    "for j in range(20):\n",
    "    print('the sample number ', j)\n",
    "    print('----------------------------------')\n",
    "    for i in range(len(names)):\n",
    "        if i ==0 or i == 2 or i == 8 or i == 9 or i == 10:\n",
    "            print(names[i],round(temp[j][i]))\n",
    "        elif i == 1:\n",
    "            print(names[i],workclass[round(temp[j][i])])\n",
    "        elif i == 3:\n",
    "            print(names[i],marital_status[round(temp[j][i])])\n",
    "        elif i == 4:\n",
    "            print(names[i],occupation[round(temp[j][i])])\n",
    "        elif i == 5:\n",
    "            print(names[i],relationship[round(temp[j][i])])\n",
    "        elif i == 6:\n",
    "            print(names[i],race[round(temp[j][i])])\n",
    "        elif i == 7:\n",
    "            print(names[i],gender[round(temp[j][i])])\n",
    "        elif i == 11:\n",
    "            print(names[i],native_country[round(temp[j][i])])\n",
    "    print('----------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 530
    },
    "executionInfo": {
     "elapsed": 184,
     "status": "error",
     "timestamp": 1640172069015,
     "user": {
      "displayName": "Rami Haffar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GivN-4FkTKiDKvMHhlJwv31uylfJn0gB7E9jeMk=s64",
      "userId": "01415100011876379673"
     },
     "user_tz": -60
    },
    "id": "3GoXsXtdOSpM",
    "outputId": "4232b5fc-57a7-4ba0-a430-d15b2ea4c280"
   },
   "outputs": [],
   "source": [
    "# print the original dataset with its categorical values\n",
    "temp = inversed_original_wrong_examples\n",
    "for j in range(20):\n",
    "    print('the sample number ', j)\n",
    "    print('----------------------------------')\n",
    "    for i in range(len(names)):\n",
    "        if i ==0 or i == 2 or i == 8 or i == 9 or i == 10:\n",
    "            print(names[i],round(temp[j][i]))\n",
    "        elif i == 1:\n",
    "            print(names[i],workclass[round(temp[j][i])])\n",
    "        elif i == 3:\n",
    "            print(names[i],marital_status[round(temp[j][i])])\n",
    "        elif i == 4:\n",
    "            print(names[i],occupation[round(temp[j][i])])\n",
    "        elif i == 5:\n",
    "            print(names[i],relationship[round(temp[j][i])])\n",
    "        elif i == 6:\n",
    "            print(names[i],race[round(temp[j][i])])\n",
    "        elif i == 7:\n",
    "            print(names[i],gender[round(temp[j][i])])\n",
    "        elif i == 11:\n",
    "            print(names[i],native_country[round(temp[j][i])])\n",
    "    print('----------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vdPSbWGnOSzO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FcJWCbBtTIwa"
   },
   "outputs": [],
   "source": [
    "# save the counterfactual examples\n",
    "np.savetxt(\"explanation.csv\", perturbed_examples, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zC1dmWT9TB-x"
   },
   "outputs": [],
   "source": [
    "# check for the correctly classified records by the provider model\n",
    "def test_images_true_classified(original_model, device, local_test_loader, targets):\n",
    "    correct_examples = []\n",
    "    true_labels = []\n",
    "    wrong_labels = []\n",
    "    counter = 0\n",
    "\n",
    "\n",
    "  # Loop over all examples in test set\n",
    "    for temp in local_test_loader:\n",
    "        counter += 1\n",
    "        data = temp\n",
    "        target = targets[counter-1]\n",
    "  # Send the data and label to the device\n",
    "        data = data.to(device) \n",
    "    # Forward pass the data through the model\n",
    "        original_model.eval()\n",
    "        with torch.no_grad():\n",
    "            output = original_model(data)\n",
    "            output = torch.sigmoid(output)\n",
    "            final_pred = torch.round(output)\n",
    "            if final_pred.item() == target:\n",
    "                correct_examples.append(data)\n",
    "                true_labels.append(final_pred.item())\n",
    "            if final_pred.item() == 0:\n",
    "                wrong_labels.append(1)\n",
    "            if final_pred.item() == 1:\n",
    "                wrong_labels.append(0)\n",
    "\n",
    "    # Return the accuracy and an adversarial example\n",
    "    return  correct_examples, true_labels, wrong_labels\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zUPFx1rhTb31"
   },
   "outputs": [],
   "source": [
    "correct_created_examples, true_predictions, wrong_target = test_images_true_classified(model, device, test_loader, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MmNL_qSpTb6p"
   },
   "outputs": [],
   "source": [
    "len(correct_created_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OH2OOd14Tb9G"
   },
   "outputs": [],
   "source": [
    "# adding the perturbations to create the counterfactual example.\n",
    "new_labels = []\n",
    "eps_all = []\n",
    "original_correct_examples = []\n",
    "counter = 0\n",
    "adversarial_example_correct_examples=[]\n",
    "# the list of features the user selects to be changed\n",
    "list_of_features = [0,2,10]\n",
    "\n",
    "\n",
    "for i in range(len(correct_created_examples)):\n",
    "    x, prediction, target = correct_created_examples[i], true_predictions[i], wrong_target[i]\n",
    "    eps = 0.0\n",
    "    while True:\n",
    "        y =  float(target)\n",
    "        y = torch.tensor([[y]])\n",
    "        target = y.to(device)\n",
    "        counter = counter + 1\n",
    "        perturbed_record = x.clone()\n",
    "        perturbed_record.requires_grad = True\n",
    "        model.eval()\n",
    "        output = local_model(perturbed_record)\n",
    "        output = torch.sigmoid(output)\n",
    "        loss = criterion(output, target)\n",
    "        output = torch.round(output)\n",
    "        loss.backward()\n",
    "        img_grad = perturbed_record.grad.data\n",
    "        with torch.no_grad():\n",
    "#         adding the perturbations according to the user preference\n",
    "            if list_of_features:\n",
    "                for h in range(len(img_grad[0])):\n",
    "                    if int(h)  in list_of_features:\n",
    "                        perturbed_record[0][h] = perturbed_record[0][h] - eps*img_grad[0][h]\n",
    "#             if the user did not select a preference\n",
    "            else:\n",
    "                perturbed_record = perturbed_record - eps*img_grad\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            output = model(perturbed_record)\n",
    "            output = torch.sigmoid(output)\n",
    "            output = torch.round(output)\n",
    "        new_label = output.item()\n",
    "        if(new_label == target):\n",
    "            adversarial_example_correct_examples.append(perturbed_record.squeeze().data.cpu().numpy())\n",
    "            original_correct_examples.append(x.squeeze().data.cpu().numpy())\n",
    "            new_labels.append(new_label)\n",
    "            eps_all.append(eps)\n",
    "            print(\"Image {} has been modified with epsilon {}\".format(i, eps))\n",
    "            break\n",
    "        eps += 20\n",
    "        if eps > 500:\n",
    "            print('record number {} there are not example'.format(i))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverse the normalization of the data set\n",
    "inversed_perturbed_record = scaler.inverse_transform(adversarial_example_correct_examples)\n",
    "inversed_original_correct_examples = scaler.inverse_transform(original_correct_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the counterfactual examples with its categorical values\n",
    "temp = inversed_perturbed_record\n",
    "for j in range(20):\n",
    "    print('the sample number ', j)\n",
    "    print('----------------------------------')\n",
    "    for i in range(len(names)):\n",
    "        if i ==0 or i == 2 or i == 8 or i == 9 or i == 10:\n",
    "            print(names[i],round(temp[j][i]))\n",
    "        elif i == 1:\n",
    "            print(names[i],workclass[round(temp[j][i])])\n",
    "        elif i == 3:\n",
    "            print(names[i],marital_status[round(temp[j][i])])\n",
    "        elif i == 4:\n",
    "            print(names[i],occupation[round(temp[j][i])])\n",
    "        elif i == 5:\n",
    "            print(names[i],relationship[round(temp[j][i])])\n",
    "        elif i == 6:\n",
    "            print(names[i],race[round(temp[j][i])])\n",
    "        elif i == 7:\n",
    "            print(names[i],gender[round(temp[j][i])])\n",
    "        elif i == 11:\n",
    "            print(names[i],native_country[round(temp[j][i])])\n",
    "    print('----------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the original dataset with its categorical values\n",
    "temp = inversed_original_correct_examples\n",
    "for j in range(20):\n",
    "    print('the sample number ', j)\n",
    "    print('----------------------------------')\n",
    "    for i in range(len(names)):\n",
    "        if i ==0 or i == 2 or i == 8 or i == 9 or i == 10:\n",
    "            print(names[i],round(temp[j][i]))\n",
    "        elif i == 1:\n",
    "            print(names[i],workclass[round(temp[j][i])])\n",
    "        elif i == 3:\n",
    "            print(names[i],marital_status[round(temp[j][i])])\n",
    "        elif i == 4:\n",
    "            print(names[i],occupation[round(temp[j][i])])\n",
    "        elif i == 5:\n",
    "            print(names[i],relationship[round(temp[j][i])])\n",
    "        elif i == 6:\n",
    "            print(names[i],race[round(temp[j][i])])\n",
    "        elif i == 7:\n",
    "            print(names[i],gender[round(temp[j][i])])\n",
    "        elif i == 11:\n",
    "            print(names[i],native_country[round(temp[j][i])])\n",
    "    print('----------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the counterfactual examples\n",
    "np.savetxt(\"explanation_correct.csv\", adversarial_example_correct_examples, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOUMbf99t5N0ck/JAwZItLd",
   "name": "Copy of read the model and create the adversarial example.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
