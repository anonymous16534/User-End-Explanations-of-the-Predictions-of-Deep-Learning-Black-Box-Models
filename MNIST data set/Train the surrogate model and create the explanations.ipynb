{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from models import *\n",
    "from utils import *\n",
    "from test import test\n",
    "from train import train\n",
    "import torch.utils.data as data\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "import copy\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new examples by pairing all the possible combinations of n images taken 2\n",
    "def samples_pair(images, labels):\n",
    "    paired = []\n",
    "    local_labels = []\n",
    "    for i in range(len(images)):\n",
    "        paired.append(images[i].numpy())\n",
    "        local_labels.append(labels[i])\n",
    "        for j in range(i, len(images)):\n",
    "            r = np.random.random()\n",
    "            if r >0.5:\n",
    "                paired.append((images[i].numpy() + images[j].numpy())/2)\n",
    "                local_labels.append(labels[i])\n",
    "    return paired, local_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed Everything\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the provider's pretrained MNIST model\n",
    "path_victim_mnist = 'pretrained_models/victim_mnist_l5.pt'\n",
    "\n",
    "victim_mnist_model = MNIST_L5().cuda()\n",
    "\n",
    "victim_mnist_model = load_state(victim_mnist_model, path_victim_mnist)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Original datasets\n",
    "mnist_trainset, mnist_testset = get_mnist_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the 0.5% of the original data set, and randomly selecting the images. \n",
    "n = len(mnist_trainset)\n",
    "d = int(len(mnist_trainset)*0.5/100)\n",
    "print(d)\n",
    "sampled_indices = np.random.choice(n, d, replace=False)\n",
    "counter = 0\n",
    "images = []\n",
    "labels = []\n",
    "for image, label in mnist_trainset:\n",
    "#     print(label)\n",
    "    if counter in sampled_indices:\n",
    "        images.append(image)\n",
    "        labels.append(label)\n",
    "#         print(label)\n",
    "    counter +=1\n",
    "#     labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the augmented data set\n",
    "paired, labels = samples_pair(images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(paired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create data set of two lists\n",
    "tensor_x = torch.Tensor(paired) # transform to torch tensor\n",
    "tensor_y = torch.Tensor(labels)\n",
    "\n",
    "emnist_trainset = TensorDataset(tensor_x,tensor_y) # create the user data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load MNIST original train and test set to data loaders\n",
    "mnist_test_loader = data.DataLoader(mnist_testset, batch_size=100, shuffle = False)\n",
    "mnist_train_loader = data.DataLoader(mnist_trainset, batch_size=100, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The provider model's accuracy on the test set\n",
    "test(victim_mnist_model, mnist_test_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the user's query loader, his model and optimizer\n",
    "# the surrogate model can be changed here to any MNIST model availble from models.py\n",
    "attacker_query_loader = data.DataLoader(emnist_trainset, batch_size=100, shuffle = False)\n",
    "attacker_mnist_model = exp_MNIST_L5_2().cuda()\n",
    "attacker_optimizer = optim.SGD(attacker_mnist_model.parameters(), \n",
    "    lr=0.001, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the provider model using the user unlabeled data. The user labels his data usig the provider model\n",
    "start = int(round(time.time()*1000)) \n",
    "labels = query_labels(victim_mnist_model, attacker_query_loader)\n",
    "time_elapsed = int(round(time.time()*1000)) -start\n",
    "# print(start.elapsed_time(end))\n",
    "print ('test time elapsed {}ms'.format(time_elapsed))\n",
    "print ('test time elapsed {}s'.format(time_elapsed/1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the user data set by merging the images with the labels obtained from the provider model.\n",
    "attacker_labled_data = get_attacker_dataset(emnist_trainset, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the training data and the watermark data to data loaders\n",
    "# Creating data indices for training and validation splits:\n",
    "validation_split = .05\n",
    "random_seed = 42\n",
    "\n",
    "dataset_size = len(attacker_labled_data)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "attacker_train_loader = torch.utils.data.DataLoader(attacker_labled_data, batch_size=100,\n",
    "                                           sampler=train_sampler)\n",
    "attacker_val_loader = torch.utils.data.DataLoader(attacker_labled_data, batch_size=100,\n",
    "                                                sampler=valid_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the user model accuracy on the test set before training. It should be random (something close to 10%)\n",
    "test(attacker_mnist_model, mnist_test_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the attacker model on the paired data set\n",
    "attacker_main_task_acc = []\n",
    "watermark_acc = []\n",
    "best_acc = 0\n",
    "start = int(round(time.time()*1000))\n",
    "for epoch in tqdm_notebook(range(100)):\n",
    "    attacker_mnist_model, loss = train(model=attacker_mnist_model, train_loader=attacker_train_loader, \n",
    "      criterion=criterion, optimizer=attacker_optimizer, local_epochs=1)\n",
    "    print('Epoch: ', epoch+1)\n",
    "    print('Attacker\\'s model acc on the validation set')\n",
    "    _, acc = test(attacker_mnist_model, attacker_val_loader, criterion)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        torch.save(attacker_mnist_model.state_dict(), 'best_mnist_attacker_model_second_different_with_MNIST.pth')\n",
    "#     print('Attacker\\'s model acc on the watermark triggers')\n",
    "#     _, wm_acc = test(attacker_mnist_model, watermark_loader, criterion)\n",
    "#     attacker_main_task_acc.append(acc)\n",
    "#     watermark_acc.append(wm_acc)\n",
    "time_elapsed = int(round(time.time()*1000)) -start\n",
    "# print(start.elapsed_time(end))\n",
    "print ('test time elapsed {}ms'.format(time_elapsed))\n",
    "print ('test time elapsed {}s'.format(time_elapsed/1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the user model\n",
    "attacker_mnist_model.load_state_dict(torch.load('Surrogate model 3.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the user model accuracy on the test set after training. It should be accurate (something close to the accuracy of the provider model)\n",
    "start = int(round(time.time()*1000))\n",
    "test(attacker_mnist_model, mnist_test_loader, criterion)\n",
    "time_elapsed = int(round(time.time()*1000)) -start\n",
    "# print(start.elapsed_time(end))\n",
    "print ('test time elapsed {}ms'.format(time_elapsed))\n",
    "print ('test time elapsed {}s'.format(time_elapsed/1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function checks the provider model for any wrong classified image and returns a\n",
    "# list with all the images that were wrongly classified.\n",
    "\n",
    "def our_test(local_model, device, local_test_loader):\n",
    "\n",
    "    # Accuracy counter\n",
    "    correct = 0\n",
    "    wrong_examples = []\n",
    "    logits = []\n",
    "    labels = []\n",
    "    counter = 0\n",
    "\n",
    "    # Loop over all examples in test set\n",
    "    for data, target in local_test_loader:\n",
    "        counter += 1\n",
    "\n",
    "        # Send the data and label to the device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # Forward pass the data through the model\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = local_model(data)\n",
    "\n",
    "        # Check for success\n",
    "    \n",
    "        final_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        if final_pred.item() == target.item():\n",
    "            correct += 1\n",
    "        else:\n",
    "\n",
    "            wrong_examples.append(data)\n",
    "            labels.append(target)\n",
    "            logits.append(output)\n",
    "        if len(labels) > 300:\n",
    "            break\n",
    "    \n",
    "    # Calculate final accuracy for this epsilon\n",
    "    print(len(local_test_loader))\n",
    "    print(correct)\n",
    "    final_acc = correct/float(len(local_test_loader))\n",
    "\n",
    "    # Return the accuracy and an adversarial example\n",
    "    return final_acc, wrong_examples, labels, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the data loader with batch size = 1, to check the images one by one. \n",
    "new_batch_size = 1\n",
    "our_test_loader = torch.utils.data.DataLoader(mnist_testset, new_batch_size, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get wrong predictions\n",
    "accuracy, wrong_examples, labels, logits = our_test(victim_mnist_model, \"cuda\", our_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_labels = [logits[i].max(1, keepdim=True)[1].item() for i in range(len(labels))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(wrong_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# adding the perturbations to create the counterfactual example.\n",
    "corrected_examples = np.zeros([len(wrong_examples)])\n",
    "perturbed_examples = []\n",
    "new_labels = []\n",
    "eps_all = []\n",
    "start = int(round(time.time()*1000))\n",
    "for i in range(len(wrong_examples)):\n",
    "    x, y, prediction = wrong_examples[i], labels[i], logits[i]\n",
    "    eps = 0.0\n",
    "#     print(i)\n",
    "    while True:\n",
    "        perturbed_image = x.clone()\n",
    "        perturbed_image.requires_grad = True\n",
    "        output = attacker_mnist_model(perturbed_image)\n",
    "        loss = F.nll_loss(output, y)\n",
    "        attacker_mnist_model.zero_grad()\n",
    "            # Calculate gradients of model in backward pass\n",
    "        loss.backward()\n",
    "        img_grad = perturbed_image.grad.data\n",
    "        perturbed_image = perturbed_image - eps*img_grad\n",
    "        output = victim_mnist_model(perturbed_image)\n",
    "        new_label = output.max(1, keepdim=True)[1]\n",
    "        if(new_label.item() == y.item()):\n",
    "            perturbed_examples.append(perturbed_image.squeeze().data.cpu().numpy())\n",
    "            new_labels.append(new_label)\n",
    "            eps_all.append(eps)\n",
    "            corrected_examples[i] = 1\n",
    "            print(\"Image {} has been modified with epsilon {}\".format(i, eps))\n",
    "            break\n",
    "        eps += 0.05\n",
    "        if eps > 0.99:\n",
    "            break\n",
    "time_elapsed = int(round(time.time()*1000)) -start\n",
    "# print(start.elapsed_time(end))\n",
    "print ('test time elapsed {}ms'.format(time_elapsed))\n",
    "print ('test time elapsed {}s'.format(time_elapsed/1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists of the images that have been explained\n",
    "real_examples = []\n",
    "real_labels = []\n",
    "wrong_predictions = []\n",
    "corrected_idx = np.where(corrected_examples == 1)\n",
    "for idx in corrected_idx[0]:\n",
    "    real_examples.append(wrong_examples[idx].squeeze().data.cpu().numpy())\n",
    "    real_labels.append(labels[idx].item())\n",
    "    wrong_predictions.append(wrong_labels[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quartlies(samples):\n",
    "    q1, med, q3 = np.percentile(samples, [25, 50, 75])\n",
    "    return q3, q3-q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boosting the perturbation added to the images\n",
    "diff = []\n",
    "tau = 8\n",
    "for i in range(len(eps_all)):\n",
    "    diff.append((real_examples[i] - perturbed_examples[i])**2)\n",
    "    q3, iqr = get_quartlies(diff[i])\n",
    "    idx = np.where(diff[i] < q3+iqr*tau)\n",
    "    diff[i][idx]*=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neglecting the non improtant perturbation and boosting the important once\n",
    "diff2 = diff\n",
    "for im in range(len(diff)):\n",
    "        for color in range(28):\n",
    "            for pixel in range(28):\n",
    "                if diff[im][color][pixel] > 0.0:\n",
    "                    diff2[im][color][pixel] = 1\n",
    "                                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real_examples[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(real_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to save the explanations\n",
    "path_wrong = 'surrogate_model_3/wrong'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing the images\n",
    "for i in range(len(perturbed_examples)):\n",
    "    for j in range(len(perturbed_examples[i])):\n",
    "        for k in range(len(perturbed_examples[i][j])):\n",
    "            perturbed_examples[i][j][k] = (perturbed_examples[i][j][k]-perturbed_examples[i].min())/(perturbed_examples[i].max()-perturbed_examples[i].min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the explanation\n",
    "for i in range(len(real_examples)):\n",
    "#    the original image\n",
    "    image1 = torch.from_numpy(real_examples[i])\n",
    "#     saving the image with the explanation\n",
    "    plt.imsave(path_wrong+'/edited/'+str(i)+\".jpg\",z)\n",
    "#     saveing the perturbtation added to the image\n",
    "    image3 = torch.from_numpy(diff[i])\n",
    "    z = image1 + image3\n",
    "    for color in range(28):\n",
    "        for pixel in range(28):\n",
    "            if z[color][pixel] > 0.0:\n",
    "                z[color][pixel] = 1\n",
    "    plt.imsave(path_wrong+'/image_with_exp/'+str(i)+\".jpg\",z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function checks the provider model for any correctly classified image and returns a\n",
    "# list with all the images that were correctly classified.\n",
    "def our_test_true_classified(local_model, device, local_test_loader):\n",
    "\n",
    "    # Accuracy counter\n",
    "    correct = 0\n",
    "    wrong_examples = []\n",
    "    logits = []\n",
    "    labels = []\n",
    "    counter = 0\n",
    "    second_label = []\n",
    "\n",
    "    # Loop over all examples in test set\n",
    "    for data, target in local_test_loader:\n",
    "        counter += 1\n",
    "\n",
    "        # Send the data and label to the device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # Forward pass the data through the model\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = local_model(data)\n",
    "#             print(output)\n",
    "#             print(counter)\n",
    "#             print(target)\n",
    "\n",
    "        # Check for success\n",
    "    \n",
    "        final_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        check = torch.topk(output, 2)\n",
    "#         print(final_pred)\n",
    "#         print(check.indices[0][1])\n",
    "#         second_label.append(check.indices[0][1])\n",
    "#         final_pred = output.argmax()\n",
    "#         print(final_pred)\n",
    "        if final_pred.item() == target.item():\n",
    "            wrong_examples.append(data)\n",
    "            labels.append(target)\n",
    "            logits.append(output)\n",
    "            second_label.append(check.indices[0][1])\n",
    "#             print('same')\n",
    "            correct += 1\n",
    "#         else:\n",
    "#             print('hi')\n",
    "\n",
    "#             wrong_examples.append(data)\n",
    "#             labels.append(target)\n",
    "#             logits.append(output)\n",
    "#         if len(labels) > 300:\n",
    "#             break\n",
    "    \n",
    "    # Calculate final accuracy for this epsilon\n",
    "#     print(len(local_test_loader))\n",
    "#     print(correct)\n",
    "    final_acc = correct/float(len(local_test_loader))\n",
    "\n",
    "    # Return the accuracy and an adversarial example\n",
    "    return final_acc, wrong_examples, labels, logits, second_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get correct predictions\n",
    "accuracy, wrong_examples, labels, logits, second = our_test_true_classified(victim_mnist_model, \"cuda\", our_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the perturbations to create the counterfactual example.\n",
    "corrected_examples = np.zeros([len(wrong_examples)])\n",
    "perturbed_examples = []\n",
    "new_labels = []\n",
    "eps_all = []\n",
    "new_counter = 0\n",
    "start =int(round(time.time()*1000))\n",
    "for i in range(len(wrong_examples)):\n",
    "    x, y, prediction = wrong_examples[i], torch.tensor([int(second[i])]).to('cuda'), logits[i]\n",
    "    eps = 0.0\n",
    "#     print(i)\n",
    "    while True:\n",
    "        perturbed_image = x.clone()\n",
    "        perturbed_image.requires_grad = True\n",
    "        output = attacker_mnist_model(perturbed_image)\n",
    "        loss = F.nll_loss(output, y)\n",
    "        attacker_mnist_model.zero_grad()\n",
    "            # Calculate gradients of model in backward pass\n",
    "        loss.backward()\n",
    "        img_grad = perturbed_image.grad.data\n",
    "        perturbed_image = perturbed_image - eps*img_grad\n",
    "        output = victim_mnist_model(perturbed_image)\n",
    "        new_label = output.max(1, keepdim=True)[1]\n",
    "        if(new_label.item() == y.item()):\n",
    "            new_counter += 1\n",
    "            perturbed_examples.append(perturbed_image.squeeze().data.cpu().numpy())\n",
    "            new_labels.append(new_label)\n",
    "            eps_all.append(eps)\n",
    "            corrected_examples[i] = 1\n",
    "            print(\"Image {} has been modified with epsilon {}\".format(i, eps))\n",
    "            break\n",
    "        eps += 0.05\n",
    "        if eps > 0.99:\n",
    "            break\n",
    "time_elapsed = int(round(time.time()*1000)) -start\n",
    "# print(start.elapsed_time(end))\n",
    "print ('test time elapsed {}ms'.format(time_elapsed))\n",
    "print ('test time elapsed {}s'.format(time_elapsed/1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_examples = []\n",
    "real_labels = []\n",
    "wrong_predictions = []\n",
    "corrected_idx = np.where(corrected_examples == 1)\n",
    "print(len(corrected_idx))\n",
    "for idx in corrected_idx[0]:\n",
    "    real_examples.append(wrong_examples[idx].squeeze().data.cpu().numpy())\n",
    "    real_labels.append(labels[idx].item())\n",
    "    wrong_predictions.append(second[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boosting the perturbation added to the images\n",
    "diff = []\n",
    "tau = 12\n",
    "for i in range(len(eps_all)):\n",
    "    diff.append((real_examples[i] - perturbed_examples[i])**2)\n",
    "    q3, iqr = get_quartlies(diff[i])\n",
    "    idx = np.where(diff[i] < q3+iqr*tau)\n",
    "    diff[i][idx]*=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neglecting the non improtant perturbation and boosting the important once\n",
    "diff2 = diff\n",
    "for im in range(len(diff)):\n",
    "        for color in range(28):\n",
    "            for pixel in range(28):\n",
    "                if diff[im][color][pixel] > 0.0:\n",
    "                    diff2[im][color][pixel] = 1\n",
    "                                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to save the explanation of the correctky classified images\n",
    "path_right = 'surrogate_model_3/right'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the explanation\n",
    "for i in range(len(real_examples)):\n",
    "#    the original image\n",
    "    image1 = torch.from_numpy(real_examples[i])\n",
    "#     saving the image with the explanation\n",
    "    plt.imsave(path_wrong+'/edited/'+str(i)+\".jpg\",z)\n",
    "#     saveing the perturbtation added to the image\n",
    "    image3 = torch.from_numpy(diff[i])\n",
    "    z = image1 + image3\n",
    "    for color in range(28):\n",
    "        for pixel in range(28):\n",
    "            if z[color][pixel] > 0.0:\n",
    "                z[color][pixel] = 1\n",
    "    plt.imsave(path_right+'/image_with_exp/'+str(i)+\".jpg\",z)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
